---
title: "How to help LLMs understand your nbdev project"
date: 2024-01-20
author: "Radek Osmulski"
description: "A practical guide to making your nbdev library LLM-friendly using llms.txt - includes automation tips and real-world examples."
---

## Overview

Want to make your nbdev library more LLM-friendly? In this tutorial, I'll show you how to add `llms.txt` to your project - a simple but powerful way to help LLMs better understand your code. You'll learn how to automatically generate `llms-ctx.txt` and `llms-ctx-full.txt` files, and serve them alongside your documentation.

The best part? These techniques aren't limited to nbdev projects. Whether you're using nbdev or not, you'll discover practical tools and ideas to make your code more accessible to LLMs!

Let's get started.

## The key ingredient

It all starts with the `llms.txt` file. Pop open your favorite text editor and get ready to write some Markdown!

Creating the `llms.txt` is not very different to writing a GitHub `README.md` file. The main difference is that you want your `llms.txt` to be broader in scope. You still want to start with a short description, but then you want to introduce links to resources that describe your project in greater detail.

The beginning is just a title, followed by a short description (the line starting with `>`). Below that you can add a few paragraphs of notes about your project.

```markdown
# FastHTML

> FastHTML is a python library which...

When writing FastHTML apps remember to:

- Thing to remember
```

How to figure out what to write in the description? A good question to ask yourself is: "How would you explain this project to a friend?"

Also, quite likely you already have some information about your project out in the world. Maybe you have a `README.md` file? Maybe you wrote a blog post about your project? A Twitter thread?

All this can be reused and repurposed! Extra points for feeding unstructured data to your LLM and asking it to summarize it for you!

The easier you make this task on yourself, the better!

Ok, so now that we have the initial bit of prose, what's next?

It is now time to add a section or two, with a title of your choice. Here you would link to additional resources that provide more detailed information about your project.

Ideally, you want these to be markdown files, but you can also probably get away with any other text format that an LLM is likely to understand (plain text, HTML, csv, etc).

```markdown
## Docs

- [Surreal](https://host/README.md): Tiny jQuery alternative with Locality of Behavior
- [FastHTML quick start](https://host/quickstart.html.md): An overview of FastHTML features

## Examples

- [Todo app](https://host/adv_app.py)
```

You can also add an optional section. The idea is the same as with the sections above -- links to useful resources. However, the optional section is special in that it will be included in `llms-ctx-full.txt` but not in `llms-ctx.txt`.

```markdown
## Optional

- [Starlette docs](https://host/starlette-sml.md): A subset of the Starlette docs
```

By providing `llms.txt` and the two autogenerated flavors `llms-ctx.txt` and `llms-ctx-full.txt`, you give your users the choice to use just the amount of information that they might need for a task at hand or that their LLM is able to handle.

And... that's it! We are all done exercising our creative muscles.

Let's take a closer look at how all the pieces work together.

## Getting the `llms-ctx.txt` and `llms-ctx-full.txt` for free

Using [llms-txt](https://llmstxt.org/intro.html) all you have to do is feed it your `llms.txt` file and out come the `llms-ctx.txt` and `llms-ctx-full.txt`!

You can use the `llms-txt` library as a CLI tool

```bash
llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt
```

or from inside a Python script.

```python
from llms_txt import *
samp = Path('llms-sample.txt').read_text()
parsed = parse_llms_file(samp)
```

So the generation of `llms-ctx.txt` and `llms-ctx-full.txt` is pretty straightforward but is there anything we could add to them, also in an automated way, to make them even more useful to our LLM?

In fact, there is! Let's meet our very next protagonist -- the tiny but mighty [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm) library.

## `apilist.txt` to the rescue

Often LLMs are able to get the big picture even for smaller libraries, but where they fall off the bandwagon are the finer details. And once an LLM starts to confabulating, it is very hard to get it back on track.

But what if we could hand an LLM a concise and up to date list of all the symbols (functions, classes, etc) in our library? This is also a great way to plug the knowledge cutoff gap between what your project looked like when the training data was collected for the training of the LLM and what it looks like right now!

Our library of choice here, [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm), is a new kid on the block and I had not been aware of its existence until I studied how the `fastcore` project handles its `llms.txt`. But the utility it provides for essentially free is too good to pass up!

You point it at your library, it does its magic, and out comes an API list, including docstrings, all in concise Markdown format!

As an example, here is the [`apilist.txt`](https://fastcore.fast.ai/apilist.txt) for [`fastcore`](https://github.com/fastai/fastcore).

Are you as excited as I am? With absolutely no effort I can now hand an LLM a list of all the symbols in any library I am interested in and can immediately start chatting with it about it!

Just to test how well it works with more traditional libraries, I cloned `numpy` and ran `pysymbol-llm` on it using the following command:

```
pysym2md numpy
```

Amazing! :)

To significantly enhance your `llms.txt` setup, generate the `apilist.txt`, serve it, and link to the URL at which it is served from your `llms.txt` file!

Ok, that sounds great, but how do we get all this to work together? Below I'll show all the configuration changes you need to make to your `nbdev` project to get you up and running in no time!

## Configuring your `nbdev` project

1. Add the `llms.txt` file to your `nbs` directory.
2. Modify `settings.ini` to include `pysymbol_llm` and `llms-txt` under `dev_requirements`.
3. Modify `nbs/_quarto.yml` to enable the generation and serving of `llms-ctx.txt`,`llms-ctx-full.txt` and `apilist.txt` (make sure you link to your `apilist.txt` from your `llms.txt` file!).

And that's it! You are all done -- commit your changes as per usual and you are ready to go!

## The final touch

If there is one thing I learned in the era of the LLM is how important it is to remove friction from the way you work. Or have fun. Or learn new things.

And one very useful source of inspiration how to achieve more of the above, regardless of the domain, is learning from others.

So why not have a couple of tabs open with `llms.txt` files of other projects you are interested in as you continue to work on your own version?

I started my own deep dive into constructing `llms.txt` files by studying the `llms.txt` of [fastcore](https://github.com/AnswerDotAI/fastcore). But there are many other great projects linked to from the [llmstxt.site](https://llmstxt.site/) and [llmstxt.cloud](https://directory.llmstxt.cloud/) directories.

And if you'd like to check out all the changes needed to add `llms.txt` to your `nbdev` project in a single, concise PR, here is how I added it [to one of my favorite libraries](https://github.com/AnswerDotAI/nbdev/pull/1485/files).

I hope you found this tutorial useful and that you will find the ideas and tools presented here helpful in your own work! In my experience, being able to hand over information to your LLM and then chat with it about is a lot of fun and a great way to learn new things!

Happy coding!
