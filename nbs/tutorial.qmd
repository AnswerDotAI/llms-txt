---
title: "How to help LLMs understand your nbdev project"
date: 2024-01-20
author: "Radek Osmulski"
description: "A practical guide to making your nbdev library LLM-friendly using llms.txt - includes automation tips and real-world examples."
---

## Overview

Want to make your nbdev library more LLM-friendly? In this tutorial, I'll show you how to add `llms.txt` to your project - a simple but powerful way to help LLMs better understand your code. You'll learn how to automatically generate `llms-ctx.txt` and `llms-ctx-full.txt` files, and serve them alongside your documentation.

The best part? These techniques aren't limited to nbdev projects. Whether you're using `nbdev` or not, you'll discover practical tools and ideas to make your code more accessible to LLMs!

Let's get started.

## The key ingredient: llms.txt

Ready to make your library LLM-friendly? It all starts with creating a `llms.txt` file. Don't worry - if you've ever written a GitHub README, you already know most of what you need!

### The basic structure

The file starts with a title and a concise description (prefixed with `>`), followed by any helpful notes about your project:

```markdown
# FastHTML

> FastHTML is a python library which...

When writing FastHTML apps remember to:

- Thing to remember
```

### Writing the description

Stuck on what to write? Here's a tip: imagine explaining your project to a friend! How would you describe it to them? Now write those words down.

Also, you probably already have great content you can adapt:
- Your project's README
- Blog posts you've written
- Social media threads
- Documentation

Pro tip: Feed selected excerpts from your existing content to an LLM and ask for a flowing summary!

The easier you make this task on yourself, the better!

### Adding resource sections

Now that we have our initial description, let's add some more details about our project.

Create a section or two (you can choose any titles that make sense for your project) and add links to resources that provide more detailed information. While Markdown files work best, don't worry if you have other formats - any text format that an LLM can understand (like plain text, HTML, or even CSV) will work just fine.

```markdown
## Docs

- [Surreal](https://host/README.md): Tiny jQuery alternative with Locality of Behavior
- [FastHTML quick start](https://host/quickstart.html.md): An overview of FastHTML features

## Examples

- [Todo app](https://host/adv_app.py)
```

The `Optional` section works just like the other sections, but any resources you put here will only appear in `llms-ctx-full.txt`, not in `llms-ctx.txt`. This lets your users choose just the right amount of context for their needs.

```markdown
## Optional

- [Starlette docs](https://host/starlette-sml.md): A subset of the Starlette docs
```

That's all there is to creating your `llms.txt`! Now let's see how to turn it into LLM-friendly context files.

## Getting the `llms-ctx.txt` and `llms-ctx-full.txt` for free

Generating context files from your `llms.txt` is surprisingly simple. The [llms-txt](https://llmstxt.org/intro.html) library does all the heavy lifting for you!

You can use it as a CLI tool:

```bash
llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt
```

Or if you prefer working in Python:

```python
from llms_txt import *
samp = Path('llms-sample.txt').read_text()
parsed = parse_llms_file(samp)
```

This will read your llms.txt and automatically fetch the content from all the linked URLs!

But wait, there's more! What if we could make these context files even more useful to LLMs? Enter [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm), a tiny but powerful tool that's going to help us do just that.

## `apilist.txt` to the rescue

LLMs are often good at understanding the big picture of smaller libraries, but they tend to struggle with the finer details. And once an LLM starts confabulating, it's very hard to get it back on track.

But what if we could hand an LLM a concise and up to date list of all the symbols (functions, classes, etc) in our library? This is also a great way to plug the knowledge cutoff gap between what your project looked like when the training data was collected for the training of the LLM and what it looks like right now!

Our library of choice here, [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm), is a new kid on the block and I had not been aware of its existence until I studied how the `fastcore` project handles its `llms.txt`. But the utility it provides for essentially free is too good to pass up!

You point it at your library, it does its magic, and out comes an API list, including docstrings, all in concise Markdown format!

As an example, here is the [apilist.txt](https://fastcore.fast.ai/apilist.txt) for [`fastcore`](https://github.com/fastai/fastcore).

Are you as excited as I am? With absolutely no effort I can now hand an LLM a list of all the symbols in any library I am interested in and can immediately start chatting with it about it!

Just to test how well it works with more traditional libraries, I cloned `numpy` and ran `pysymbol-llm` on it using the following command:

```bash
pysym2md numpy
```
Amazing! :)

To significantly enhance your `llms.txt` setup, generate the `apilist.txt`, serve it, and link to the URL at which it is served from your `llms.txt` file!

### Configuring your `nbdev` project

Now that we have all the pieces ready, let's put them together! Here are the three steps needed to get your LLM-friendly docs up and running:

1. Add your `llms.txt` file to the `nbs` directory of your project.

2. Tell nbdev about the new dependencies by adding these lines to your `dev_requirements` in `settings.ini`:
```
dev_requirements = pysymbol_llm llms-txt
```
3. Configure Quarto to generate and serve the context files. Add these lines to your `nbs/_quarto.yml`:
```
project:
  type: website
  pre-render:
    - pysym2md --output_file apilist.txt nbdev
  post-render:
    - llms_txt2ctx llms.txt --optional true --save_nbdev_fname llms-ctx-full.txt
    - llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt
  resources:
    - "*.txt"
```

Remember to link to your `apilist.txt` from your `llms.txt` file!

And that's it! Commit your changes as usual and your library is ready to chat with LLMs.

## The final touch

If there's one thing I've learned in the era of LLMs, it's the importance of removing friction - whether you're working, learning, or just having fun. And one of the best ways to do that? Learning from others!

Why not keep a few tabs open with `llms.txt` files from other projects while working on your own? I started my journey by studying the `llms.txt` of [fastcore](https://github.com/AnswerDotAI/fastcore), and found many more great examples in the [llmstxt.site](https://llmstxt.site/) and [llmstxt.cloud](https://directory.llmstxt.cloud/) directories.

Want to see how all these pieces fit together? Here's a [complete example](https://github.com/AnswerDotAI/nbdev/pull/1485/files) of adding `llms.txt` to one of my favorite libraries.

I hope you found this tutorial helpful! Being able to chat with an LLM about your code is not just practical - it's a fantastic way to learn and explore. Have fun making your library LLM-friendly!

Happy coding!
